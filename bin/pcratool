#!/usr/bin/python3
SVER = '0.0.5-dev'

##############################################################################
# pcratool - Pacemaker Cluster Report Analysis Tool
# Copyright (c) 2025 SUSE LLC
#
# Description:  Analyzes HB report archives for known issues
# Modified:     2025 Sep 12
#
##############################################################################
#
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; version 3 of the License.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, see <http://www.gnu.org/licenses/>.
#
#  Authors/Contributors:
#    Jason Record <jason.record@suse.com>
#    Raine Curtis <raine.curtis@suse.com>
#
##############################################################################

import os
import re
import sys
import json
import signal
import shutil
import fileinput
from datetime import datetime as dt
import socket
import getopt
import smtplib
import subprocess
import configparser
import pprint # for debugging only, remove before release
import xml.dom.minidom

config_file = '/etc/pcratool/pcratool.conf'
width = 0
description_width = 0
progress_bar_active = True
tool_name = os.path.basename(__file__)

def separator_line(use_char = '#'):
    print("{}".format(use_char*width))

def title():
    separator_line()
    print("#   Pacemaker Cluster Report Analysis Tool, v" + SVER)
    separator_line()
    print()

def usage():
    display = "  {:33} {}"
    print("Usage: {} [OPTIONS] [/path/to/hb_report]".format(tool_name))
    print()
    print("OPTIONS")
    print(display.format('-h, --help', "Displays this screen"))
    print(display.format('-b, --batch', "Batch mode that disables the progress bar"))
    print(display.format('-d, --debug', "Use log level 4"))
    print(display.format('-k, --keep', "Do not delete extracted directories"))
    print(display.format('-n, --normal', "Use log level 2, default log level: Minimal"))
    print(display.format('-o <path>, --output <path>', "Report file output directory"))
    print(display.format('-q, --quiet', "Use log level 0"))
    print(display.format('-r, --remove', "Remove archive files leaving only the Report file. Ignored in debug mode."))
    print(display.format('-t, --type', "Report file output type, options: json, html, all. Default: html"))
    print(display.format('-v, --verbose', "Use log level 3"))
    print(display.format('-x <path>, --dirpath_extract_here <path>', "Extract any HB report archives to this alternate extraction directory"))
#    print(display.format('-l <level>, --log_level <level>', "Set log level, default: Minimal"))
#    print(display.format('', "0 Quiet, 1 Minimal, 2 Normal, 3 Verbose, 4 Debug"))
    print()

def option_error(msg):
    print(msg)
    print()
    usage()
    sys.exit(1)

def signal_handler(sig, frame):
    print("\n\nAborting...\n")
    sys.exit(1)

def separate_entry(msg, count):
    if count > 1:
        msg.min()
        msg.separator(msg.LOG_MIN, '=')
        msg.min()

def config_entry(_entry, trailer = ''):
    formatted_entry = _entry.strip('\"\'')
    if( len(trailer) > 0 ):
        if len(formatted_entry) > 0:
            if not formatted_entry.endswith(trailer):
                formatted_entry = formatted_entry + str(trailer)
    return formatted_entry

class ProgressBar():
    """Initialize and update progress bar class"""

    def __init__(self, prefix, total):
        self.base_len = int(width)
        self.desc_width = int(description_width) + 1
        self.bar_width = self.base_len
        self.prefix = prefix
        self.prefix_size = len(self.prefix)
        self.total = int(total)
        self.count = 0
        self.out = sys.stdout
        if self.prefix_size > self.desc_width:
            self.bar_width = self.base_len - self.prefix_size - 2
        else:
            self.bar_width = self.base_len - self.desc_width - 2
        self.display = "{:" + str(self.desc_width) + "s}[{}{}] {:3g}% {:3g}/{}"

    def __str__(self):
        return 'class %s(\n  prefix=%r \n  bar_width=%r \n  total=%r\n)' % (self.__class__.__name__, self.prefix, self.bar_width, self.total)

    def set_prefix(self, _prefix):
        self.prefix = _prefix
        if ( self.bar_width_orig == self.base_len ):
            self.bar_width = self.base_len - self.prefix_size - 2
        else:
            self.bar_width = self.bar_width_orig

    def set_total(self, _new_total):
        self.total = _new_total

    def inc_count(self, increment = 1):
        """Increments one by default"""
        if self.count < self.total:
            self.count += increment

    def get_total(self):
        return self.total

    def get_count(self):
        return self.count

    def update(self):
        percent_complete = int(100*self.count/self.total)
        current_progress = int(self.bar_width*self.count/self.total)
        print(self.display.format(self.prefix, "#"*current_progress, "."*(self.bar_width-current_progress), percent_complete, self.count, self.total), end='\r', file=self.out, flush=True)

    def finish(self):
        if self.count != self.total:
            self.count = self.total
            self.update()
        print("", flush=True, file=self.out)

class DisplayMessages():
    "Display message string for a given log level"
    LOG_QUIET = 0    # turns off messages
    LOG_MIN = 1    # minimal messages
    LOG_NORMAL = 2    # normal, but significant, messages
    LOG_VERBOSE = 3    # detailed messages
    LOG_DEBUG = 4    # debug-level messages
    LOG_LEVELS = {0: "Quiet", 1: "Minimal", 2: "Normal", 3: "Verbose", 4: "Debug" }

    def __init__(self):
        self.level = self.LOG_MIN # instance default
        self.desc_width = 30 # instance default
        self.msg_display = "{:" + str(self.desc_width) + "}"
        self.msg_display_pair = self.msg_display + " = {}"

    def __str__ (self):
        return "class %s(level=%r)" % (self.__class__.__name__,self.level)

    def set_width(self, width_value):
        self.desc_width = width_value
        self.msg_display = "{:" + str(self.desc_width) + "}"
        self.msg_display_pair = self.msg_display + " = {}"

    def get_level(self):
        return self.level

    def get_level_str(self):
        return self.LOG_LEVELS[self.level]

    def set_level(self, level):
        if( level >= self.LOG_DEBUG ):
            self.level = self.LOG_DEBUG
        else:
            self.level = level

    def validate_level(self, level):
        validated_level = -1
        if( level.isdigit() ):
            validated_level = int(level)
        else:
            argstr = level.lower()
            if( argstr.startswith("qui") ):
                validated_level = self.LOG_QUIET
            elif( argstr.startswith("min") ):
                validated_level = self.LOG_MIN
            elif( argstr.startswith("norm") ):
                validated_level = self.LOG_NORMAL
            elif( argstr.startswith("verb") ):
                validated_level = self.LOG_VERBOSE
            elif( argstr.startswith("debug") ):
                validated_level = self.LOG_DEBUG

        return validated_level


    def __write_paired_msg(self, level, msgtag, msgstr):
        if( level <= self.level ):
            print(self.msg_display_pair.format(msgtag, msgstr))

    def __write_msg(self, level, msgtag):
        if( level <= self.level ):
            print(self.msg_display.format(msgtag))

    def quiet(self, msgtag = None, msgstr = None):
        "Write messages even if quiet is set"
        if msgtag:
            if msgstr:
                self.__write_paired_msg(self.LOG_QUIET, msgtag, msgstr)
            else:
                self.__write_msg(self.LOG_QUIET, msgtag)
        else:
            if( self.level >= self.LOG_QUIET ):
                print()

    def min(self, msgtag = None, msgstr = None):
        "Write the minium amount of messages"
        if msgtag:
            if msgstr:
                self.__write_paired_msg(self.LOG_MIN, msgtag, msgstr)
            else:
                self.__write_msg(self.LOG_MIN, msgtag)
        else:
            if( self.level >= self.LOG_MIN ):
                print()

    def normal(self, msgtag = None, msgstr = None):
        "Write normal, but significant, messages"
        if msgtag:
            if msgstr:
                self.__write_paired_msg(self.LOG_NORMAL, msgtag, msgstr)
            else:
                self.__write_msg(self.LOG_NORMAL, msgtag)
        else:
            if( self.level >= self.LOG_NORMAL ):
                print()

    def verbose(self, msgtag = None, msgstr = None):
        "Write more verbose informational messages"
        if msgtag:
            if msgstr:
                self.__write_paired_msg(self.LOG_VERBOSE, msgtag, msgstr)
            else:
                self.__write_msg(self.LOG_VERBOSE, msgtag)
        else:
            if( self.level >= self.LOG_VERBOSE ):
                print()

    def debug(self, msgtag = None, msgstr = None):
        "Write all messages, including debug level"
        if msgtag:
            updated_msgtag = "+ " + msgtag
            if msgstr:
                self.__write_paired_msg(self.LOG_DEBUG, updated_msgtag, msgstr)
            else:
                self.__write_msg(self.LOG_DEBUG, updated_msgtag)
        else:
            if( self.level >= self.LOG_DEBUG ):
                print()

    def separator(self, required_level, use_char = '#'):
        if self.level >= required_level:
            print("{}".format(use_char*width))

def valid_archive_dir(msg, given_path):
    TEST_FILES = ['description.txt', 'analysis.txt']
    if not os.access(given_path, os.R_OK | os.X_OK):
        msg.min(" ERROR:", "Directory permission denied: {0}".format(given_path))
        msg.min(" * Suggestion", "Try sudo {} {}".format(tool_name, given_path))
        return False
    else:
        for test_file in TEST_FILES:
            file_path = given_path + '/' + test_file
            if not os.access(file_path, os.F_OK):
                msg.min(" ERROR:", "Invalid cluster report directory: {0}".format(given_path))
                msg.min(" * Missing", "{0}".format(file_path))
                return False
            elif not os.access(file_path, os.R_OK):
                msg.min(" ERROR:", "Read file permission denied: {0}".format(file_path))
                msg.min(" * Suggestion", "Try sudo {} {}".format(tool_name, given_path))
                return False
    return True

def extract_archive(msg, tarball):
    path_in_tarball = ''
    archfile = tarball['path'] 
    archdir = tarball['dirpath_extract_here']
    msg.verbose(" Extracting File", archfile)
    msg.debug("archdir", archdir)
    cmd = "tar -xvf "  + archfile + " -C " + archdir
    msg.debug('Process Command', cmd)
    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)
    stdout, stderr = process.communicate()
    outfile = stdout.splitlines()[0]
    msg.debug("outfile", outfile)
    rc = process.returncode
    if( rc > 0 ):
        print(" Error: Cannot extract tar file", file=sys.stderr)
        print(stderr, file=sys.stderr)
        print(file=sys.stderr)
        sys.exit(7)
    else:
        path_in_tarball = archdir + '/' + os.path.dirname(outfile).split("/")[0]
        msg.verbose(' Embedded Directory', path_in_tarball)

    return path_in_tarball

def i_am_root():
    if not os.environ.get("SUDO_UID") and os.geteuid() != 0:
        return False
    return True

def clean_up(msg, data):
    if data['source_data']['valid']:
        if data['source_data']['remove_directory']:
            try:
                shutil.rmtree(data['source_data']['dirpath_data_source'])
            except:
                True

        if data['source_data']['remove_tarball']:
            try:
                os.remove(data['source_data']['path'])
            except:
                True

def evaluate_given_path(msg, given_path):
    given_results = {
        'exists': False, 
        'given_path': given_path, 
        'path': '', 
        'head': '', 
        'tail': '', 
        'type': '', 
        'tail_mime_type': '',
        'head_read': False, 'head_write': False, 'head_exec': False, 
        'tail_read': False, 'tail_write': False, 'tail_exec': False, 
    }

    if os.path.exists(given_path):
        given_results['exists'] = True
        given_results['path'] = os.path.abspath(given_path)
        given_results['head'] = os.path.dirname(given_results['path'])
        given_results['tail'] = os.path.basename(given_results['path'])
        if os.access(given_results['path'], os.R_OK):
            given_results['tail_read'] = True
        if os.access(given_results['path'], os.W_OK):
            given_results['tail_write'] = True
        if os.access(given_results['path'], os.X_OK):
            given_results['tail_exec'] = True
        if given_results['tail_read']:
            if os.path.isfile(given_results['path']):
                given_results['type'] = 'file'
                cmd = "file --brief --mime-type " + given_path
                msg.debug('Process Command', cmd)
                process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)
                stdout, stderr = process.communicate()
                given_results['tail_mime_type'] = stdout.strip()
            elif os.path.isdir(given_results['path']):
                given_results['type'] = 'dir'
                given_results['tail_mime_type'] = 'inode/directory'
        if os.access(given_results['head'], os.R_OK):
            given_results['head_read'] = True
        if os.access(given_results['head'], os.W_OK):
            given_results['head_write'] = True
        if os.access(given_results['head'], os.X_OK):
            given_results['head_exec'] = True

    msg.debug("Evaluate Path", given_results)
    return given_results

def check_extraction_path_given(msg, config_file, extract_path_cmd, extract_path_config):
    path_data = {}

    if extract_path_cmd:
        path_data = evaluate_given_path(msg, extract_path_cmd)
        msg.verbose("Extraction Directory", "Evaluating path given on command line: {0}".format(path_data['given_path']))
        if path_data['exists']:
            if path_data['tail_write']:
                path_data['dirpath_extract_here'] = path_data['path']
                path_data['extract_here_for_reports'] = True
                msg.normal("Extraction Directory Change", "From command line: {0}".format(path_data['path']))
            else:
                msg.min("Extraction Directory", "Evaluating path given on command line: {0}".format(path_data['given_path']))
                msg.min(" Error", "Write permisson denied, cannot extract file to {0}".format(path_data['path']))
                msg.min(" * Suggestion", "Fix the -x, --dirpath_extract_here directory\n")
                sys.exit(2)
        else:
            msg.min("Extraction Directory", "Evaluating path given on command line: {0}".format(path_data['given_path']))
            msg.min(" Error", "Directory not found - {0}".format(path_data['given_path']))
            msg.min(" * Suggestion", "Try mkdir -p {0} or fix the -x, --dirpath_extract_here directory\n".format(path_data['given_path']))
            sys.exit(2)
    elif extract_path_config:
        path_data = evaluate_given_path(msg, extract_path_config)
        msg.verbose("Extraction Directory", "Evaluating path given in the config file: {0}".format(path_data['given_path']))
        if path_data['exists']:
            if path_data['tail_write']:
                path_data['dirpath_extract_here'] = path_data['path']
                path_data['extract_here_for_reports'] = True
                msg.normal("Extraction Directory Change", "From config file: {0}".format(path_data['path']))
            else:
                msg.min("Extraction Directory", "Evaluating path given in the config file: {0}".format(path_data['given_path']))
                msg.min(" Error", "Write permisson denied, cannot extract file to {0}".format(path_data['path']))
                msg.min(" * Suggestion", "Fix the extract_path in {0}\n".format(config_file))
                sys.exit(2)
        else:
            msg.min("Extraction Directory", "Evaluating path given in the config file: {0}".format(path_data['given_path']))
            msg.min(" Error", "Directory not found - {0}".format(path_data['given_path']))
            msg.min(" * Suggestion", "Try mkdir -p {0} or fix the extract_path in {1}\n".format(path_data['given_path'], config_file))
            sys.exit(2)

    return path_data

def check_report_path_given(msg, config_file, report_path_cmd, report_path_config):
    path_data = {}

    if report_path_cmd:
        path_data = evaluate_given_path(msg, report_path_cmd)
        msg.verbose("Report Directory", "Evaluating path given on command line: {0}".format(path_data['given_path']))
        if path_data['exists']:
            if path_data['tail_write']:
                msg.normal("Report Directory Change", "From command line: {0}".format(path_data['path']))
            else:
                msg.min("Report Directory", "Evaluating path given on command line: {0}".format(path_data['given_path']))
                msg.min(" Error", "Write permisson denied, cannot create report file in {0}".format(path_data['path']))
                msg.min(" * Suggestion", "Fix the -o, --output directory\n")
                sys.exit(3)
        else:
            msg.min("Report Directory", "Evaluating path given on command line: {0}".format(path_data['given_path']))
            msg.min(" Error", "Directory not found - {0}".format(path_data['given_path']))
            msg.min(" * Suggestion", "Try mkdir -p {0} or fix the -o, --output directory\n".format(path_data['given_path']))
            sys.exit(3)
    elif report_path_config:
        path_data = evaluate_given_path(msg, report_path_config)
        msg.verbose("Report Directory", "Evaluating path given in the config file: {0}".format(path_data['given_path']))
        if path_data['exists']:
            if path_data['tail_write']:
                msg.normal("Report Directory Change", "From config file: {0}".format(path_data['path']))
            else:
                msg.min("Report Directory", "Evaluating path given in the config file: {0}".format(path_data['given_path']))
                msg.min(" Error", "Write permisson denied, cannot create report file in {0}".format(path_data['path']))
                msg.min(" * Suggestion", "Fix the report_output_path in {0}\n".format(config_file))
                sys.exit(3)
        else:
            msg.min("Report Directory", "Evaluating path given in the config file: {0}".format(path_data['given_path']))
            msg.min(" Error", "Directory not found - {0}".format(path_data['given_path']))
            msg.min(" * Suggestion", "Try mkdir -p {0} or fix the report_output_path in {1}\n".format(path_data['given_path'], config_file))
            sys.exit(3)

    return path_data

def _write_diff_file(filename, filepath, diff_content):
    msg.min(" Differences Data File", filepath)
    try:
        with open(filepath, "w") as f:
            for line in diff_content:
                f.write(line + "\n")
            f.close()
    except Exception as e:
        msg.min(" Cannot write file {}".format(filename), "{}".format(str(e)))

def _get_cluster_basics(msg, file_data, cluster_data):
    ##### description.txt
    filename = "description.txt"
    msg.debug("_get_cluster_basics: File", filename)
    filepath = file_data['dirpath_data_source'] + "/" + filename
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.min(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if filedata:
        for line in filedata:
            if line.startswith("Date: "):
                cluster_data['hb_report_date'] = line.split(' ', 1)[1]
                msg.debug("> get hb_report_date", cluster_data['hb_report_date'])
            if line.startswith("By: "):
                cluster_data['hb_report_by'] = line.split(' ', 1)[1]
                msg.debug("> get hb_report_by", cluster_data['hb_report_by'])

    ##### analysis.txt
    msg.min("Evalutating Analysis", "Differences")
    filename = "analysis.txt"
    msg.debug("_get_cluster_basics: File", filename)
    filepath = file_data['dirpath_data_source'] + "/" + filename
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.min(" Missing {}".format(filename), "{}".format(str(e)))
        cluster_data['data_complete'] = False
        msg.min(" WARNING:", "Cluster data incomplete, no {} file found.".format(filename))
        msg.min("          All cluster_data[insync_*] values are wrong.")
        filedata = ''

    in_state = False
    diff_file = ''
    diff_content = []
    filepath_diff = ''
    next_line = ''
    if filedata:
        for i, line in enumerate(filedata):
            if i < len(filedata) - 1:  # Check if a next element exists
                next_line = filedata[i + 1]
            else:
                next_line = ''

            if in_state:
                if next_line.startswith('Diff') or next_line.startswith('Checking problems with '):
                    filepath_diff = file_data['dirpath_reports'] + "/" + diff_file
                    _write_diff_file(diff_file, filepath_diff, diff_content)
                    cluster_data['diffs'][diff_key] = {}
                    cluster_data['diffs'][diff_key]['filepath_diff'] = filepath_diff
                    cluster_data['diffs'][diff_key]['count'] = len(diff_content)
                    in_state = False
                    diff_file = ''
                    diff_content = []
                else:
                    diff_content.append(line)
            else:
                if "Diff members.txt" in line:
                    msg.debug("> evaluate", "insync_members_txt")
                    if "OK" in line:
                        cluster_data['insync_members_txt'] = True
                    else:
                        cluster_data['insync_members_txt'] = False
                        in_state = True
                        diff_file = "diff_members.txt"
                        diff_key = "diff_members_txt"
                        msg.debug(">", "differences found")

                if "Diff crm_mon.txt" in line:
                    msg.debug("> evaluate", "insync_crm_mon_txt")
                    if "OK" in line:
                        cluster_data['insync_crm_mon_txt'] = True
                    else:
                        cluster_data['insync_crm_mon_txt'] = False
                        in_state = True
                        diff_file = "diff_crm_mon.txt"
                        diff_key = "diff_crm_mon_txt"
                        msg.debug(">", "differences found")

                if "Diff corosync.conf" in line:
                    msg.debug("> evaluate", "insync_corosync_conf")
                    if "OK" in line:
                        cluster_data['insync_corosync_conf'] = True
                    else:
                        cluster_data['insync_corosync_conf'] = False
                        in_state = True
                        diff_file = "diff_corosync_conf.txt"
                        diff_key = "diff_corosync_conf"
                        msg.debug(">", "differences found")

                if "Diff sysinfo.txt" in line:
                    msg.debug("> evaluate", "insync_sysinfo_txt")
                    if "OK" in line:
                        cluster_data['insync_sysinfo_txt'] = True
                    else:
                        cluster_data['insync_sysinfo_txt'] = False
                        in_state = True
                        diff_file = "diff_sysinfo.txt"
                        diff_key = "diff_sysinfo_txt"
                        msg.debug(">", "differences found")

                if "Diff cib.xml" in line:
                    msg.debug("> evaluate", "insync_cib_xml")
                    if "OK" in line:
                        cluster_data['insync_cib_xml'] = True
                    else:
                        cluster_data['insync_cib_xml'] = False
                        in_state = True
                        diff_file = "diff_cib_xml.txt"
                        diff_key = "diff_cib_xml"
                        msg.debug(">", "differences found")

    return cluster_data

def _parse_permissions_txt(msg, dirpath, node_name, cluster_data, found_permissions):
    ##### permissions.txt
    filename = "permissions.txt"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_permissions_txt: File", filename)

    msg.debug("> evaluate", "permissions_valid")
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        cluster_data['nodes'][node_name]['permissions_valid'] = None
        filedata = ''

    if filedata:
        found_permissions = True
        cluster_data['nodes'][node_name]['permissions_valid'] = True
        for line in filedata:
            if "OK" not in line:
                cluster_data['nodes'][node_name]['permissions_valid'] = False
                cluster_data['permissions_valid_all_nodes'] = 0

    return [cluster_data, found_permissions]

def _parse_sysinfo_txt(msg, dirpath, node_name, cluster_data, found_sysinfo):
    ##### sysinfo.txt
    filename = "sysinfo.txt"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_sysinfo_txt: File", filename)
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    tmp_dist_list = []
    if filedata:
        found_sysinfo = True
        msg.debug(">", "pkg versions and summary info")
        if 'sysinfo' not in cluster_data['nodes'][node_name]:
            cluster_data['nodes'][node_name]['sysinfo'] = {}
        for line in filedata:
            line = line.lstrip()
            if line.startswith("CRM Version: "):
                cluster_data['nodes'][node_name]['sysinfo']['crm'] = line.split()[2]

            if line.startswith("corosync "):
                cluster_data['nodes'][node_name]['sysinfo']['corosync'] = line.split()[1]
                tmp_dist_list = line.split()
                del tmp_dist_list[-1]
                del tmp_dist_list[0:3]
            elif re.search(r"^corosync-[0-9]", line):
                tmp_ver1 = line.split('-', 1)[1]
                tmp_ver2 = tmp_ver1.split('.')
                del tmp_ver2[-1]
                tmp_ver1 = '.'.join(tmp_ver2)
                cluster_data['nodes'][node_name]['sysinfo']['corosync'] = tmp_ver1

            if line.startswith("pacemaker "):
                cluster_data['nodes'][node_name]['sysinfo']['pacemaker'] = line.split()[1]
            elif re.search(r"^pacemaker-[0-9]", line):
                tmp_ver1 = line.split('-', 1)[1]
                tmp_ver2 = tmp_ver1.split('.')
                del tmp_ver2[-1]
                tmp_ver1 = '.'.join(tmp_ver2)
                cluster_data['nodes'][node_name]['sysinfo']['pacemaker'] = tmp_ver1

            if line.startswith("resource-agents "):
                cluster_data['nodes'][node_name]['sysinfo']['resource-agents'] = line.split()[1]
            elif re.search(r"^resource-agents-[0-9]", line):
                tmp_ver1 = line.split('-', 2)[2]
                tmp_ver2 = tmp_ver1.split('.')
                del tmp_ver2[-1]
                tmp_ver1 = '.'.join(tmp_ver2)
                cluster_data['nodes'][node_name]['sysinfo']['resource-agents'] = tmp_ver1

            if line.startswith("sbd "):
                cluster_data['nodes'][node_name]['sysinfo']['sbd'] = line.split()[1]
            elif re.search(r"^sbd-[0-9]", line):
                tmp_ver1 = line.split('-', 1)[1]
                tmp_ver2 = tmp_ver1.split('.')
                del tmp_ver2[-1]
                tmp_ver1 = '.'.join(tmp_ver2)
                cluster_data['nodes'][node_name]['sysinfo']['sbd'] = tmp_ver1

            if line.startswith("Platform: "):
                cluster_data['nodes'][node_name]['sysinfo']['platform'] = line.split()[-1]
            if line.startswith("Kernel release: "):
                cluster_data['nodes'][node_name]['sysinfo']['kernel'] = line.split()[-1]
            if line.startswith("Architecture: "):
                cluster_data['nodes'][node_name]['sysinfo']['arch'] = line.split()[-1]
            if line.startswith("Distribution: "):
                dist = line.split(' ', 1)[1]
                if "SUSE Linux Enterprise" in dist:
                    last_word = dist.split()[-1]
                    if "SP" in last_word:
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_major'] = dist.split()[-2]
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_minor'] = last_word.replace("SP", '')
                        cluster_data['nodes'][node_name]['sysinfo']['distribution'] = dist
                    else:
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_major'] = dist.split()[-1]
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_minor'] = "0"
                        cluster_data['nodes'][node_name]['sysinfo']['distribution'] = dist
                else:
                    if tmp_dist_list:
                        cluster_data['nodes'][node_name]['sysinfo']['distribution'] = " ".join(tmp_dist_list)
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_major'] = tmp_dist_list[-1]
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_minor'] = ''
                    else:
                        cluster_data['nodes'][node_name]['sysinfo']['distribution'] = ''
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_major'] = ''
                        cluster_data['nodes'][node_name]['sysinfo']['os_version_minor'] = ''
                msg.verbose(" Distribution found", cluster_data['nodes'][node_name]['sysinfo']['distribution'])

    return [cluster_data, found_sysinfo]

def _get_sysstats_section(msg, filedata, section):
    content = []
    found = False
    in_section = False
    next_line = ''

    for i, line in enumerate(filedata):
        if i < len(filedata) - 1:  # Check if a next element exists
            next_line = filedata[i + 1]
        else:
            next_line = ''

        if in_section:
            if next_line.startswith('#####'):
                in_section = False
            else:
                content.append(line)
                found = True
        else:
            if line.startswith('#####') and section in line:
                in_section = True

    return [content, found]

def _parse_sysstats_txt(msg, dirpath, node_name, cluster_data, found_sysstats):
    ##### sysstats.txt
    filename = "sysstats.txt"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_sysstats_txt: File", filename)
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if filedata:
        found_sysstats = True
        if "sysstats" not in cluster_data['nodes'][node_name]:
            cluster_data['nodes'][node_name]['sysstats'] = {}

        # uptime
        uptime_info, found = _get_sysstats_section(msg, filedata, '"uptime"')
        cluster_data['nodes'][node_name]['sysstats']['uptime'] = -1 # in minutes
        cluster_data['nodes'][node_name]['sysstats']['tasks'] = {'load_average': []} # the average number of jobs in the run queue over the last 1, 5 and 15 minutes.
        if found is True:
            for entry in uptime_info:
                if 'average' in entry:
                    updays = 0
                    uphrs = 0
                    upmin = 0
                    values = re.split('[:,]', entry)
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['load_average'].append(float(values[-3])) # last 1 minute, index 0
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['load_average'].append(float(values[-2])) # last 5 minutes, index 1
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['load_average'].append(float(values[-1])) # last 15 minutes, index 2
                    values = entry.split('up')[1].split(",")[0]
                    if "days" in values:
                        updays = values.split("days")[0]
                        uphrs, upmin = values.split("days")[1].split(":")
                    elif "day" in values:
                        updays = 1
                        uphrs, upmin = values.split("day")[1].split(":")
                    else:
                        uphrs, upmin = values.split(":")
                    updays = int(updays)
                    uphrs = int(uphrs)
                    upmin = int(upmin)
                    upall = (updays * 1440) + (uphrs * 60) + upmin
                    cluster_data['nodes'][node_name]['sysstats']['uptime'] = upall

        # cpuinfo
        cpu_info, found = _get_sysstats_section(msg, filedata, "cat /proc/cpuinfo")
        cluster_data['nodes'][node_name]['sysstats']['cpu'] = { 'count': 0 }
        if found is True:
            for entry in cpu_info:
                if entry.startswith("processor"):
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['count'] += 1

        # memory from top output
        top_info, found = _get_sysstats_section(msg, filedata, "top -b -n")
        cluster_data['nodes'][node_name]['sysstats']['tasks'].update({'total': -1, 'running': -1, 'sleeping': -1, 'stopped': -1, 'zombie': -1})
        cluster_data['nodes'][node_name]['sysstats']['cpu'].update({'user': -1.0, 'system': -1.0, 'nice': -1.0, 'idle': -1.0, 'wait': -1.0, 'hard_int': -1.0, 'soft_int': -1.0, 'steal_time': -1.0})
        cluster_data['nodes'][node_name]['sysstats']['mem'] = { 'total': -1, 'used': -1, 'avail': -1, 'avail_percent': -1 }
        cluster_data['nodes'][node_name]['sysstats']['swap'] = { 'total': -1, 'used': -1 }

        if found is True:
            for entry in top_info:
                if entry.startswith("Tasks:"):
                    value = entry.split()
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['total'] = int(value[1])
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['running'] = int(value[3])
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['sleeping'] = int(value[5])
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['stopped'] = int(value[7])
                    cluster_data['nodes'][node_name]['sysstats']['tasks']['zombie'] = int(value[9])
                if entry.startswith('%Cpu(s):'):
                    value = entry.split(',')
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['user'] = float(value[0].split()[1])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['system'] = float(value[1].split()[0])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['nice'] = float(value[2].split()[0])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['idle'] = float(value[3].split()[0])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['wait'] = float(value[4].split()[0])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['hard_int'] = float(value[5].split()[0])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['soft_int'] = float(value[6].split()[0])
                    cluster_data['nodes'][node_name]['sysstats']['cpu']['steal_time'] = float(value[7].split()[0])
                if entry.startswith("MiB Mem"):
                    values = re.split(r"[,:]", entry)
                    for value in values:
                        if "total" in value:
                            if "." in value:
                                mem_value = value.split('.')[0]
                            elif "+" in value:
                                mem_value = value.split('+')[0]
                            cluster_data['nodes'][node_name]['sysstats']['mem']['total'] = int(mem_value)
                        elif "used" in value:
                            if "." in value:
                                mem_value = value.split('.')[0]
                            elif "+" in value:
                                mem_value = value.split('+')[0]
                            cluster_data['nodes'][node_name]['sysstats']['mem']['used'] = int(mem_value)
                if entry.startswith("MiB Swap"):
                    values = re.split(r"[,:]", entry)
                    for value in values:
                        if "total" in value:
                            if "." in value:
                                mem_value = value.split('.')[0]
                            elif "+" in value:
                                mem_value = value.split('+')[0]
                            cluster_data['nodes'][node_name]['sysstats']['swap']['total'] = int(mem_value)
                        elif "avail" in value:
                            values = value.split('d. ') # split the used and available value
                            break
                    for value in values:
                        if "use" in value:
                            if "." in value:
                                mem_value = value.split('.')[0]
                            elif "+" in value:
                                mem_value = value.split('+')[0]
                            cluster_data['nodes'][node_name]['sysstats']['swap']['used'] = int(mem_value)
                        elif "avail" in value:
                            if "." in value:
                                mem_value = value.split('.')[0]
                            elif "+" in value:
                                mem_value = value.split('+')[0]
                            cluster_data['nodes'][node_name]['sysstats']['mem']['avail'] = int(mem_value)

                    cluster_data['nodes'][node_name]['sysstats']['mem']['avail_percent'] = int(100-((cluster_data['nodes'][node_name]['sysstats']['mem']['total'] - cluster_data['nodes'][node_name]['sysstats']['mem']['avail'])*100/cluster_data['nodes'][node_name]['sysstats']['mem']['total']))

    return [cluster_data, found_sysstats]

def _parse_crm_mon_txt(msg, dirpath, node_name, cluster_data, found_crm_mon):
    ##### crm_mon.txt
    filename = "crm_mon.txt"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_crm_mon_txt: File", filename)
    stop_early = False
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if filedata:
        found_crm_mon = True
        for line in filedata:
            line = line.strip()
            if line.startswith('* '):
                line = line[2:]

            if line.startswith('##'):
                if stop_early:
                    break
                else:
                    stop_early = True
                    continue
            if "Resource management is DISABLED" in line:
                msg.debug(">", "found cluster maintenance status")
                cluster_data['cluster_maintenance'] = True
            if "partition with quorum" in line:
                msg.debug(">", "found quorum status")
                cluster_data['has_quorum'] = True
            if "Current DC" in line:
                dc_node_name = line.split()[2]
                if dc_node_name not in cluster_data['nodes']:
                    msg.debug(">", "Added {} from {}".format(dc_node_name, filename))
                    cluster_data['nodes'][dc_node_name] = {}
                    cluster_data['nodes'][dc_node_name]['is_included'] = False
                msg.debug(">", "Added DC node {} from {}".format(node_name, filename))
                cluster_data['nodes'][dc_node_name]['is_dc_crm'] = True
            if " nodes configured" in line:
                msg.debug(">", "cnt_nodes_configured")
                value = line.split()[0]
                if value.isdigit():
                    cluster_data['cnt_nodes_configured'] = int(value)
            if " resource instances configured" in line:
                msg.debug(">", "cnt_resources_configured")
                value = line.split()[0]
                if value.isdigit():
                    cluster_data['cnt_resources_configured'] = int(value)
            if " resources configured" in line:
                msg.debug(">", "cnt_resources_configured")
                value = line.split()[0]
                if value.isdigit():
                    cluster_data['cnt_resources_configured'] = int(value)
            if "Online: [" in line:
                entry = re.findall(r"\[(.*?)\]", line)
                cluster_data['nodes_online'] = entry[0].strip().split()
                msg.debug("> nodes_online", "added {}".format(cluster_data['nodes_online']))
            if "OFFLINE: [" in line:
                entry = re.findall(r"\[(.*?)\]", line)
                cluster_data['nodes_offline'] = entry[0].strip().split()
                msg.debug("> nodes_offline", "added {}".format(cluster_data['nodes_offline']))
            if "maintenance" in line:
                entry = re.findall(r"Node (.*?): maintenance", line)
                if entry:
                    if entry[0] not in cluster_data['nodes_maintenance']:
                        msg.debug(">", "nodes_maintenance list, appended {}".format(entry[0]))
                        cluster_data['nodes_maintenance'].append(entry[0])
            if "UNCLEAN" in line:
                entry = re.findall(r"Node (.*?): UNCLEAN", line)
                if entry:
                    if entry[0] not in cluster_data['nodes_unclean']:
                        msg.debug(">", "nodes_unclean list, appended {}".format(entry[0]))
                        cluster_data['nodes_unclean'].append(entry[0])
            if "standby" in line:
                entry = re.findall(r"Node (.*?): standby", line)
                if entry:
                    if entry[0] not in cluster_data['nodes_standby']:
                        msg.debug(">", "nodes_standby list, appended {}".format(entry[0]))
                        cluster_data['nodes_standby'].append(entry[0])
            if "pending" in line:
                entry = re.findall(r"Node (.*?): pending", line)
                if entry:
                    if entry[0] not in cluster_data['nodes_pending']:
                        msg.debug(">", "nodes_pending list, appended {}".format(entry[0]))
                        cluster_data['nodes_pending'].append(entry[0])
            if "stonith:" in line:
                cluster_data['stonith']['enabled'] = True
                if "stonith:external/sbd" in line:
                    cluster_data['stonith']['sbd']['found'] = True
                    msg.debug(">", "stonith:external/sbd found")
                else:
                    entry = re.findall(r"\(stonith:(.*)\):", line)
                    if entry:
                        _type = entry[0]
                        if _type not in cluster_data['stonith']:
                            cluster_data['stonith'][_type] = {}
                            cluster_data['stonith'][_type]['found'] = True
                    msg.debug(">", "stonith:{} found".format(_type))


    return [cluster_data, found_crm_mon]

def _parse_members_txt(msg, dirpath, cluster_data, found_members):
    ##### members.txt
    filename = "members.txt"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_members_txt: File", filename)
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if filedata:
        found_members = True
        node_list = []
        for line in filedata:
            node_list = line.split()
        for node_name in node_list:
            if node_name not in cluster_data['nodes']:
                msg.debug(">", "Added {} from {}".format(node_name, filename))
                cluster_data['nodes'][node_name] = {}
                cluster_data['nodes'][node_name]['is_included'] = False

    return [cluster_data, found_members]

def _get_nodes_system_details(msg, file_data, cluster_data):
    found_permissions = False
    found_sysinfo = False
    found_sysstats = False
    subfolders = [ f.path for f in os.scandir(file_data['dirpath_data_source']) if f.is_dir() ]
    for node_data_source in subfolders:
        node_name = os.path.basename(node_data_source)
        msg.verbose("Processing system details", "from {} node directory".format(node_name))
        if node_name not in cluster_data['nodes']:
            cluster_data['nodes'][node_name] = {}
            msg.debug("_get_nodes_system_details:", "Added {} from {}".format(node_name, "directory"))

        cluster_data, found_sysinfo = _parse_sysinfo_txt(msg, node_data_source, node_name, cluster_data, found_sysinfo)
        cluster_data, found_sysstats = _parse_sysstats_txt(msg, node_data_source, node_name, cluster_data, found_sysstats)
        cluster_data, found_permissions = _parse_permissions_txt(msg, node_data_source, node_name, cluster_data, found_permissions)

    if not found_permissions:
        msg.verbose("Warning:", "No permissions.txt file found")
    if not found_sysinfo:
        msg.verbose("Warning:", "No sysinfo.txt file found")

    return cluster_data

def _parse_cib_xml_cfg(msg, dirpath, node_name, cluster_data):
    msg.verbose("Parsing cluster CIB ", "from {} node directory".format(node_name))
    ##### crm_mon.txt
    filename = "cib.xml"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_crm_mon_txt: File", filename)
    stop_early = False
    try:
        with open(filepath) as f:
            #xtree = ET.parse(f)
            xdom = xml.dom.minidom.parse(f)
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ""

    print("BEFORE: Cluster data for node:", node_name)
    pprint.pprint(cluster_data)
    print('-'*80)
    cib_data = {}

    if xdom:
        cib_element = xdom.getElementsByTagName("cib")[0]
        for attr in cib_element.attributes.keys():
            msg.debug("> cib attribute", "{} = {}".format(attr, cib_element.getAttribute(attr)))  
            #if attr in ["crm_feature_set", "cib-last-written", "update-origin", "have-quorum"]:
            cib_data[attr] = cib_element.getAttribute(attr)

        # Walking through cib.xml to get configuration values
        cfg = xdom.getElementsByTagName("configuration")

        cib_data["cluster_property_sets"] = {}
        # Get cluster properties
        crm_configs = cfg[0].getElementsByTagName("crm_config")
        if len(crm_configs) > 0:
            cluster_property_sets  = crm_configs[0].getElementsByTagName("cluster_property_set")
            if len(cluster_property_sets) > 0:
                for cps in cluster_property_sets:
                    for attr in cps.attributes.keys():
                        cib_data["cluster_property_sets"][cps.getAttribute(attr)] = {}
                        nvpairs = cps.getElementsByTagName("nvpair")
                        for nv in nvpairs:
                            nv_name = nv.getAttribute("name")
                            nv_value = nv.getAttribute("value")
                            cib_data["cluster_property_sets"][cps.getAttribute(attr)][nv_name] = nv_value

        # Get node attributes
        nodes_parent = xdom.getElementsByTagName("nodes")
        nodes = nodes_parent[0].getElementsByTagName("node")
        if len(nodes) > 0:
            if "nodes" not in cib_data.keys():
                cib_data["nodes"] = {}
            for node in nodes:
                node_uname= node.getAttribute("uname")
                msg.debug("> cib node", "Found node {}".format(node_uname))
                if node_uname not in cib_data:
                    cib_data["nodes"][node_uname] = {}
                instance_attributes = node.getElementsByTagName("instance_attributes")
                nvpairs = instance_attributes[0].getElementsByTagName("nvpair") 
                for nvp in nvpairs:
                    nv_name = nvp.getAttribute("name")
                    nv_value = nvp.getAttribute("value")
                    cib_data["nodes"][node_uname][nv_name] = nv_value

        # Get resources 
        resources_parent = xdom.getElementsByTagName("resources")
        if len(resources_parent) > 0:
            cib_data["resources"] = {}
            # Get primitives
            primitives = resources_parent[0].getElementsByTagName("primitive")
            if len(primitives) > 0:
                if "primitives" not in cib_data["resources"]:
                    cib_data["resources"]["primitives"] = {}
                for primitive in primitives:
                    primitive_id = primitive.getAttribute("id")
                    cib_data["resources"]["primitives"][primitive_id] = {}
                    for attr in primitive.attributes.keys():
                        if attr not in ["id"]:
                            cib_data["resources"]["primitives"][primitive_id][attr] = primitive.getAttribute(attr)
                        instance_attributes = primitive.getElementsByTagName("instance_attributes")
                        if len(instance_attributes) > 0:
                            cib_data["resources"]["primitives"][primitive_id]["params"] = {}
                            nvpairs = instance_attributes[0].getElementsByTagName("nvpair")
                            for nv in nvpairs:
                                nv_name = nv.getAttribute("name")
                                nv_value = nv.getAttribute("value")
                                cib_data["resources"]["primitives"][primitive_id]["params"][nv_name] = nv_value

            # Get groups
            # Get tags: group > meta_attributes > primitives > instance-attributes > operations > op
            groups = resources_parent[0].getElementsByTagName("group")
            if len(groups) > 0: 
                if "groups" not in cib_data["resources"]:
                    cib_data["resources"]["groups"] = {}
                for group in groups:
                    group_id = group.getAttribute("id")
                    cib_data["resources"]["groups"][group_id] = {}
                    # Get group attributes
                    for attr in group.attributes.keys():
                        if attr not in ["id"]:
                            cib_data["resources"]["groups"][group_id][attr] = group.getAttribute(attr)
                    meta_attributes = group.getElementsByTagName("meta_attributes")
                    if len(meta_attributes) > 0:
                        cib_data["resources"]["groups"][group_id]["meta"] = {}
                        nvpairs = meta_attributes[0].getElementsByTagName("nvpair")
                        for nv in nvpairs:
                            nv_name = nv.getAttribute("name")
                            nv_value = nv.getAttribute("value")
                            cib_data["resources"]["groups"][group_id]["meta"][nv_name] = nv_value
                    # Get primivites under groups
                    group_primitives = group.getElementsByTagName("primitive")
                    if len(group_primitives) > 0:
                        if "primitives" not in cib_data["resources"]["groups"][group_id]:
                            cib_data["resources"]["groups"][group_id]["primitives"] = {}
                        for primitive in group_primitives:
                            primitive_id = primitive.getAttribute("id")
                            cib_data["resources"]["groups"][group_id]["primitives"][primitive_id] = {}
                            # Get primitive attributes
                            for attr in primitive.attributes.keys():
                                if attr not in ["id"]:
                                    cib_data["resources"]["groups"][group_id]["primitives"][primitive_id][attr] = primitive.getAttribute(attr)
                            instance_attributes = primitive.getElementsByTagName("instance_attributes")
                            if len(instance_attributes) > 0:
                                cib_data["resources"]["groups"][group_id]["primitives"][primitive_id]["params"] = {}
                                nvpairs = instance_attributes[0].getElementsByTagName("nvpair")
                                # Get nvpairs under attrs
                                for nv in nvpairs:
                                    nv_name = nv.getAttribute("name")
                                    nv_value = nv.getAttribute("value")
                                    cib_data["resources"]["groups"][group_id]["primitives"][primitive_id]["params"][nv_name] = nv_value
                            # Get operations
                            operations = primitive.getElementsByTagName("operations")
                            ops = operations[0].getElementsByTagName("op")
                            if len(ops) > 0:
                                cib_data["resources"]["groups"][group_id]["primitives"][primitive_id]["operations"] = {}
                                for op in ops:
                                    op_name = op.getAttribute("name")
                                    cib_data["resources"]["groups"][group_id]["primitives"][primitive_id]["operations"][op_name] = {}
                                    for attr in op.attributes.keys():
                                        cib_data["resources"]["groups"][group_id]["primitives"][primitive_id]["operations"][op_name][attr] = op.getAttribute(attr)

            # Get master/slave (multi-state resources)
            masters = resources_parent[0].getElementsByTagName("master")
            if len(masters) > 0:
                cib_data["resources"]["masters"] = {}
            for master in masters:
                master_id = master.getAttribute("id")
                cib_data["resources"]["masters"][master_id] = {}
                meta_attributes = master.getElementsByTagName("meta_attributes")
                if len(meta_attributes) > 0:
                    cib_data["resources"]["masters"][master_id]["meta"] = {}
                    nvpairs = meta_attributes[0].getElementsByTagName("nvpair")
                    for nv in nvpairs:
                        nv_name = nv.getAttribute("name")
                        nv_value = nv.getAttribute("value")
                        cib_data["resources"]["masters"][master_id]["meta"][nv_name] = nv_value
                primitives = master.getElementsByTagName("primitive")
                if len(primitives) > 0:
                    cib_data["resources"]["masters"][master_id]["primitives"] = {}
                    for primitive in primitives:
                        primitive_id = primitive.getAttribute("id")
                        cib_data["resources"]["masters"][master_id]["primitives"][primitive_id] = {}
                        # Get primitive attributes
                        for attr in primitive.attributes.keys():
                            if attr not in ["id"]:
                                cib_data["resources"]["masters"][master_id]["primitives"][primitive_id][attr] = primitive.getAttribute(attr)
                        instance_attributes = primitive.getElementsByTagName("instance_attributes")
                        if len(instance_attributes) > 0:
                            cib_data["resources"]["masters"][master_id]["primitives"][primitive_id]["params"] = {}
                            nvpairs = instance_attributes[0].getElementsByTagName("nvpair")
                            # Get nvpairs under attrs
                            for nv in nvpairs:
                                nv_name = nv.getAttribute("name")
                                nv_value = nv.getAttribute("value")
                                cib_data["resources"]["masters"][master_id]["primitives"][primitive_id]["params"][nv_name] = nv_value
                        # Get operations
                        operations = primitive.getElementsByTagName("operations")
                        ops = operations[0].getElementsByTagName("op")
                        if len(ops) > 0:
                            cib_data["resources"]["masters"][master_id]["primitives"][primitive_id]["operations"] = {}
                            for op in ops:
                                op_name = op.getAttribute("name")
                                cib_data["resources"]["masters"][master_id]["primitives"][primitive_id]["operations"][op_name] = {}
                                for attr in op.attributes.keys():
                                    cib_data["resources"]["masters"][master_id]["primitives"][primitive_id]["operations"][op_name][attr] = op.getAttribute(attr)

            # Get clones
            clones = resources_parent[0].getElementsByTagName("clone")  
            if len(clones) > 0:
                cib_data["resources"]["clones"] = {}
                for clone in clones:
                    clone_id = clone.getAttribute("id")
                    cib_data["resources"]["clones"][clone_id] = {}
                    meta_attributes = clone.getElementsByTagName("meta_attributes")
                    if len(meta_attributes) > 0:
                        cib_data["resources"]["clones"][clone_id]["meta"] = {}
                        nvpairs = meta_attributes[0].getElementsByTagName("nvpair")
                        for nv in nvpairs:
                            nv_name = nv.getAttribute("name")
                            nv_value = nv.getAttribute("value")
                            cib_data["resources"]["clones"][clone_id]["meta"][nv_name] = nv_value
                    primitives = clone.getElementsByTagName("primitive")
                    if len(primitives) > 0:
                        cib_data["resources"]["clones"][clone_id]["primitives"] = {}
                        for primitive in primitives:
                            primitive_id = primitive.getAttribute("id")
                            cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id] = {}
                            # Get primitive attributes
                            for attr in primitive.attributes.keys():
                                if attr not in ["id"]:
                                    cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id][attr] = primitive.getAttribute(attr)
                            instance_attributes = primitive.getElementsByTagName("instance_attributes")
                            if len(instance_attributes) > 0:
                                cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id]["params"] = {}
                                nvpairs = instance_attributes[0].getElementsByTagName("nvpair")
                                # Get nvpairs under attrs
                                for nv in nvpairs:
                                    nv_name = nv.getAttribute("name")
                                    nv_value = nv.getAttribute("value")
                                    cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id]["params"][nv_name] = nv_value
                            # Get operations
                            operations = primitive.getElementsByTagName("operations")
                            ops = operations[0].getElementsByTagName("op")
                            if len(ops) > 0:
                                cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id]["operations"] = {}
                                for op in ops:
                                    op_name = op.getAttribute("name")
                                    cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id]["operations"][op_name] = {}
                                    for attr in op.attributes.keys():
                                        cib_data["resources"]["clones"][clone_id]["primitives"][primitive_id]["operations"][op_name][attr] = op.getAttribute(attr)

        # Get constraints
        constraints = cfg[0].getElementsByTagName("constraints")
        if len(constraints) > 0:
            cib_data["constraints"] = {}
            rsc_colocation = constraints[0].getElementsByTagName("rsc_colocation")
            if len(rsc_colocation) > 0:
                cib_data["constraints"]["colocations"] = {}
                for colocation in rsc_colocation:
                    colocation_id = colocation.getAttribute("id")
                    cib_data["constraints"]["colocations"][colocation_id] = {}
                    for attr in colocation.attributes.keys():
                        cib_data["constraints"]["colocations"][colocation_id][attr] = colocation.getAttribute(attr)

         # Get resource defaults
        rsc_defaults = xdom.getElementsByTagName("rsc_defaults")
        if len(rsc_defaults) > 0:
            cib_data["rsc_defaults"] = {}
            meta_attributes = rsc_defaults[0].getElementsByTagName("meta_attributes")
            if len(meta_attributes) > 0:
                rsc_defaults_id =  meta_attributes[0].getAttribute("id")
                print(f"Resource Defaults ID: {rsc_defaults_id}")
                cib_data["rsc_defaults"][rsc_defaults_id] =   {}
                nvpairs = meta_attributes[0].getElementsByTagName("nvpair")
                if len(nvpairs) > 0:
                    for nv in nvpairs:
                        nv_name = nv.getAttribute("name")
                        nv_value = nv.getAttribute("value")
                        cib_data["rsc_defaults"][rsc_defaults_id][nv_name] = nv_value

        # Get operation defaults
        op_defaults = xdom.getElementsByTagName("op_defaults")
        if len(op_defaults) > 0:
            cib_data["op_defaults"] = {}
            meta_attributes = op_defaults[0].getElementsByTagName("meta_attributes")
            if len(meta_attributes) > 0:
                op_defaults_id =  meta_attributes[0].getAttribute("id")
                print(f"Operation Defaults ID: {op_defaults_id}")
                cib_data["op_defaults"][op_defaults_id] =   {}
                nvpairs = meta_attributes[0].getElementsByTagName("nvpair")
                if len(nvpairs) > 0:
                    for nv in nvpairs:
                        nv_name = nv.getAttribute("name")
                        nv_value = nv.getAttribute("value")
                        cib_data["op_defaults"][op_defaults_id][nv_name] = nv_value

    if cluster_data.get("cib") is None:
        cluster_data["cib"] = cib_data
    if cluster_data.get('insync_cib_xml') is False:
        if cluster_data['nodes'].get(node_name) is None:
            print(f"Node {node_name} not found in cluster_data['nodes'], creating entry.")
            cluster_data['nodes'][node_name] = {}
        cluster_data['nodes'][node_name]['cib'] = cib_data
    pprint.pprint(cib_data, indent=4)
    print('-' * 80)
    pprint.pprint(cluster_data)
    print("Node: ", node_name)
    return cluster_data

def _parse_cib_xml_node_state(msg, dirpath, node_name, cluster_data):
    msg.verbose("Parsing cluster CIB ", "from {} node directory".format(node_name))
    ##### crm_mon.txt
    filename = "cib.xml"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_crm_mon_txt: File", filename)
    stop_early = False
    try:
        with open(filepath) as f:
            #xtree = ET.parse(f)
            xdom = xml.dom.minidom.parse(f)
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if cluster_data.get('cib') is None:
        cluster_data['cib'] = {}

    if xdom:
        cib_element = xdom.getElementsByTagName('cib')[0]
        for attr in cib_element.attributes.keys():
            msg.debug("> cib attribute", "{} = {}".format(attr, cib_element.getAttribute(attr)))  
            #if attr in ['crm_feature_set', 'cib-last-written', 'update-origin', 'have-quorum']:
            cluster_data['cib'][attr] = cib_element.getAttribute(attr)

        # walking through cib.xml to get values
        # cib > node_state > transient_attributes > instance_attributes > nvpair
        node_element = xdom.getElementsByTagName('node_state')
        for node in node_element:
            uname =  node.getAttribute("uname")
            if uname not in cluster_data['nodes']:
                cluster_data['nodes'][uname] = {}
            if 'cib_state' not in cluster_data['nodes'][uname]:
                cluster_data['nodes'][uname]['cib_state'] = {}
            for attr in node.attributes.keys():
                    cluster_data['nodes'][uname]['cib_state'][attr] = node.getAttribute(attr)

            trans_attrs = node.getElementsByTagName('transient_attributes')
            for t_attr in trans_attrs:
                cluster_data['nodes'][uname]['cib_node_attrs'] = {}
                for attr in t_attr.attributes.keys():
                    cluster_data['nodes'][uname]['cib_node_attrs'][str(t_attr.getAttribute(attr))] = {}
                    i_attrs = t_attr.getElementsByTagName('instance_attributes')
                    for i_attr in i_attrs:
                       i_attr_id = i_attr.getAttribute('id').split('-')[1]
                       nv_pairs = i_attr.getElementsByTagName('nvpair')
                       for nv in nv_pairs:
                        nv_name = nv.getAttribute('name')
                        nv_value = nv.getAttribute('value')
                        cluster_data['nodes'][uname]['cib_node_attrs'][i_attr_id][nv_name] = nv_value
            
            node_resources = {}
            lrm_resources = node.getElementsByTagName('lrm_resource')
            for lrm in lrm_resources:
                resource_id = lrm.getAttribute("id")
                if resource_id not in node_resources:
                    node_resources[resource_id] = {}
                for attr in ['type', 'class']:
                    node_resources[resource_id][attr] = lrm.getAttribute(attr)
                    lrm_ops = lrm.getElementsByTagName('lrm_rsc_op')

                    if node_resources[resource_id].get('operations') is None:
                        node_resources[resource_id]['operations'] = {}
                    for op in lrm_ops:
                        op_name = op.getAttribute('operation')
                        on_node = op.getAttribute('on_node')
                        rc_code = op.getAttribute('rc-code')
                        node_resources[resource_id]['operations'][op_name] = {
                            'on_node': on_node,
                            'rc_code': rc_code
                        }

            if cluster_data['insync_cib_xml'] is True:
                cluster_data['resources'] = node_resources
                break
            else:
                cluster_data['nodes'][uname]['cib_resources'] = node_resources

    return cluster_data


def _get_nodes_cluster_cib(msg, file_data, cluster_data):
    found_crm_xml = False
    subfolders = [ f.path for f in os.scandir(file_data['dirpath_data_source']) if f.is_dir() ]
    for node_data_source in subfolders:
        node_name = os.path.basename(node_data_source)
        msg.verbose("Processing cluster CIB info", "from {} node directory".format(node_name))
<<<<<<< HEAD
        if node_name not in cluster_data['nodes']:
            cluster_data['nodes'][node_name] = {}
=======
        if node_name in cluster_data['nodes']:
            if  cluster_data['nodes'][node_name] is None:
                cluster_data['nodes'][node_name] = {}
>>>>>>> 37ac33d (Cleaned up _parse_cib function)
            msg.debug("_get_nodes_cluster_cib:", "Added {} from {}".format(node_name, "directory"))
            cluster_data = _parse_cib_xml_cfg(msg, node_data_source, node_name, cluster_data)

    return cluster_data
            

def _get_nodes_cluster_crm(msg, file_data, cluster_data):
    found_crm_mon = False
    found_members = False
    subfolders = [ f.path for f in os.scandir(file_data['dirpath_data_source']) if f.is_dir() ]
    for node_data_source in subfolders:
        node_name = os.path.basename(node_data_source)
        msg.verbose("Processing cluster CRM info", "from {} node directory".format(node_name))
        if node_name not in cluster_data['nodes']:
            cluster_data['nodes'][node_name] = {}
            msg.debug("_get_nodes_cluster_crm:", "Added {} from {}".format(node_name, "directory"))

        msg.debug("_get_nodes_cluster_crm:", "incremented cnt_nodes_included and set is_included on {}".format(node_name))
        cluster_data['cnt_nodes_included'] += 1
        cluster_data['nodes'][node_name]['is_included'] = True

        ##### DC and RUNNING files
        file_dc = node_data_source + "/DC"
        file_running = node_data_source + "/RUNNING"
        if os.path.exists(file_dc):
            msg.debug(">", "Added DC node {} from {}".format(node_name, "directory"))
            cluster_data['nodes'][node_name]['is_dc_local'] = True
        else:
            cluster_data['nodes'][node_name]['is_dc_local'] = False

        if os.path.exists(file_running):
            cluster_data['nodes'][node_name]['is_running'] = True
        else:
            cluster_data['nodes'][node_name]['is_running'] = False

        cluster_data, found_crm_mon = _parse_crm_mon_txt(msg, node_data_source, node_name, cluster_data, found_crm_mon)
        cluster_data, found_members = _parse_members_txt(msg, node_data_source, cluster_data, found_members)

    # find missing nodes excluded from members.txt or directories
    node_states = ['unclean', 'standby', 'pending', 'maintenance', 'offline', 'online']
    msg.debug("_get_nodes_cluster_crm:", "Find missing nodes from lists")
    for state in node_states:
        check_nodes = "nodes_" + state
        msg.debug("> {}".format(check_nodes), "cluster_data[nodes] {}".format(cluster_data['nodes'].keys()))
        for node_name in cluster_data[check_nodes]:
            if node_name not in cluster_data['nodes']:
                msg.debug(">", "Added {} from {}".format(node_name, check_nodes))
                cluster_data['nodes'][node_name] = {}
                cluster_data['nodes'][node_name]['is_included'] = False

    # if node directories don't have crm_mon.txt, check source directory
    if not found_crm_mon:
        filename = "crm_mon.txt"
        filepath = file_data['dirpath_data_source'] + "/" + filename
        if os.path.exists(filepath):
            msg.verbose("Found {}".format(filename), filepath)
            cluster_data, found_crm_mon = _parse_crm_mon_txt(msg, file_data['dirpath_data_source'], node_name, cluster_data, found_crm_mon)

    if not found_crm_mon:
        msg.min("WARNING:", "Cluster data incomplete, no crm_mon.txt file found.")
    if not found_members:
        msg.verbose("Warning:", "No members.txt file found")

    cluster_data['data_complete'] = found_crm_mon

    return cluster_data

def _parse_sbd_txt(msg, dirpath, cluster_data, found_sbd_txt):
    ##### sbd.txt
    filename = "sbd.txt"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_sbd_txt: File", filename)
    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if filedata:
        found_sbd_txt = True
        for line in filedata:
            if line and line[0].isdigit():
                entry = line.split()
                server = entry[1]
                status = entry[2]
                if 'nodes' not in cluster_data['stonith']['sbd']:
                    cluster_data['stonith']['sbd']['nodes'] = {}
                if server not in cluster_data['stonith']['sbd']['nodes']:
                    cluster_data['stonith']['sbd']['nodes'][server] = {'slots': []}
                cluster_data['stonith']['sbd']['nodes'][server]['slots'].append(entry)

    return [cluster_data, found_sbd_txt]

def _parse_sbd(msg, dirpath, cluster_data, found_sbd):
    ##### sbd
    filename = "sbd"
    filepath = dirpath + "/" + filename
    msg.debug("_parse_sbd: File", filename)

    try:
        with open(filepath) as f:
            filedata = f.read().splitlines()
            f.close()
    except Exception as e:
        msg.verbose(" Missing {}".format(filename), "{}".format(str(e)))
        filedata = ''

    if filedata:
        found_sbd = True
        for line in filedata:
            if line.startswith("#"):
                continue
            line = line.strip()
            if line and "=" in line:
                key, value = line.split('=', 1)
                if 'SBD_DEVICE' in key:
                    device_list = value.strip().strip('"').strip("'").split(';')
                    cluster_data['stonith']['sbd']['config'][key.strip()] = device_list
                else:
                    cluster_data['stonith']['sbd']['config'][key.strip()] = value.strip().strip('"').strip("'")

    return [cluster_data, found_sbd]

def _get_stonith_sbd(msg, file_data, cluster_data):
    subfolders = [ f.path for f in os.scandir(file_data['dirpath_data_source']) if f.is_dir() ]
    found_sbd_txt = False
    found_sbd = False
    cluster_data['stonith']['sbd']['all_clear'] = -1
    for node_data_source in subfolders:
        node_name = os.path.basename(node_data_source)
        msg.verbose("Processing SBD info", "from {} node directory".format(node_name))

        cluster_data, found_sbd_txt = _parse_sbd_txt(msg, node_data_source, cluster_data, found_sbd_txt)
        cluster_data, found_sbd = _parse_sbd(msg, node_data_source, cluster_data, found_sbd)

    if not found_sbd:
        msg.verbose("Warning:", "No sbd configuration file found")
    if found_sbd_txt:
        msg.debug("_get_stonith_sbd:", "Calculating stonith SBD all_clear and is_clear")
        cluster_data['stonith']['sbd']['all_clear'] = 1
        for node_name in cluster_data['stonith']['sbd']['nodes'].keys():
            cluster_data['stonith']['sbd']['nodes'][node_name]['is_clear'] = True
            for status in cluster_data['stonith']['sbd']['nodes'][node_name]['slots']:
                if 'clear' not in status:
                    cluster_data['stonith']['sbd']['nodes'][node_name]['is_clear'] = False
                    cluster_data['stonith']['sbd']['all_clear'] = 0
    else:
        msg.verbose("Warning:", "No sbd.txt configuration file found")

    return cluster_data

def _get_cluster_nodes_state(msg, file_data, cluster_data):
    msg.debug("_get_cluster_nodes_state:", "Determining node states from nodes lists")
    for node_name in cluster_data['nodes'].keys():
        if node_name in cluster_data['nodes_unclean']:
            cluster_data['nodes'][node_name]['is_unclean'] = True
        else:
            cluster_data['nodes'][node_name]['is_unclean'] = False

        if node_name in cluster_data['nodes_pending']:
            cluster_data['nodes'][node_name]['is_pending'] = True
        else:
            cluster_data['nodes'][node_name]['is_pending'] = False

        if node_name in cluster_data['nodes_standby']:
            cluster_data['nodes'][node_name]['is_standby'] = True
        else:
            cluster_data['nodes'][node_name]['is_standby'] = False

        if node_name in cluster_data['nodes_maintenance']:
            cluster_data['nodes'][node_name]['is_maintenance'] = True
        else:
            if cluster_data['cluster_maintenance']:
                cluster_data['nodes'][node_name]['is_maintenance'] = True
            else:
                cluster_data['nodes'][node_name]['is_maintenance'] = False

        if 'is_running' not in cluster_data['nodes'][node_name]:
            msg.debug("> is_running", "Check in nodes_online: {}".format(node_name))
            if node_name in cluster_data['nodes_online']:
                cluster_data['nodes'][node_name]['is_running'] = True
            else:
                cluster_data['nodes'][node_name]['is_running'] = False

        if 'is_dc_local' not in cluster_data['nodes'][node_name]:
            msg.debug("> is_dc_local", "No DC file was found for {}".format(node_name))
            cluster_data['nodes'][node_name]['is_dc_local'] = False

        if 'is_dc_crm' not in cluster_data['nodes'][node_name]:
            msg.debug("> is_dc_crm", "Not Current DC for {} in crm_mon.txt".format(node_name))
            cluster_data['nodes'][node_name]['is_dc_crm'] = False

    return cluster_data

def get_cluster_data(msg, file_data):
    cluster_data = {
        'data_complete': True,
        'nodes': {},
        'stonith': {
            'sbd': {
                'found': False,
                'config': {},
            },
            'enabled': False,
        },
        'diffs': {},
        'cnt_nodes_configured': -1,
        'cnt_nodes_included': 0,
        'cnt_resources_configured': -1,
        'has_quorum': False,
        'cluster_maintenance': False,
        'nodes_online': [],
        'nodes_offline': [],
        'nodes_unclean': [],
        'nodes_pending': [],
        'nodes_standby': [],
        'nodes_maintenance': [],
        'permissions_valid_all_nodes': 1,
        'insync_members_txt': False,
        'insync_crm_mon_txt': False,
        'insync_corosync_conf': False,
        'insync_sysinfo_txt': False,
        'insync_cib_xml': False,
   }

    cluster_data = _get_cluster_basics(msg, file_data, cluster_data)
    cluster_data = _get_nodes_system_details(msg, file_data, cluster_data)
    cluster_data = _get_nodes_cluster_crm(msg, file_data, cluster_data)
    cluster_data = _get_nodes_cluster_cib(msg, file_data, cluster_data)
#    else:
#        cluster_data = _get_nodes_cluster_crm(msg, file_data, cluster_data)
#        cluster_data = _get_nodes_cluster_cib(msg, file_data, cluster_data)

    if cluster_data['stonith']['sbd']['found']:
        cluster_data = _get_stonith_sbd(msg, file_data, cluster_data)
    cluster_data = _get_cluster_nodes_state(msg, file_data, cluster_data)
    if cluster_data['cnt_nodes_configured'] != cluster_data['cnt_nodes_included']:
        cluster_data['permissions_valid_all_nodes'] = -1

    return cluster_data

def _create_reports_path(msg, data):
    try:
        os.makedirs(data['dirpath_reports'], exist_ok=True)
    except OSError as e:
        msg.min(" ERROR:", "{}".format(str(e)))
        sys.exit(13)

    return

def synchronize_log_files(msg, report_data):
    msg.min("Log Files", "Combining and Sorting")
    EX_OK = 0
    MAX_HEADER_LINES = 100
    date_formats = [
    #   List of all possible log file data formats
    #   ['date format', string trim amount left to right, unless negative which if right to left],
        [],
        ['%Y-%m-%dT%H:%M:%S.%f', 26],
        ['%b %d %H:%M:%S.%f', 19],
        ['%b %d %H:%M:%S', 15],
    ]
    log_files = {
    #   The date format to use for each log file and the preferred order to test which is used
    #   'log file': [list of indeces to possible date_formats],
        'pacemaker.log': [2, 3, 1],
        'corosync.log': [3, 2, 1],
        'journal_corosync.log': [1, 2, 3],
        'journal_pacemaker.log': [1, 2, 3],
        'journal_sbd.log': [1, 2, 3],
        'ha-log.txt': [1, 2, 3],
    }
    f_names = []

    def _get_date_format(f_path, date_formats, eval_order):
        header_lines = []
        date_info = []
        idx_date = 0
        empty = 0
        len_fnames = 0

        # Read the first MAX_HEADER_LINES header_lines to determine the date format from the f_path given
        with open(f_path, 'r') as f:
            msg.debug("_get_date_format", f_path)
            line_count = 0
            for line in f:
                line_count += 1
                header_lines.append(line.strip())
                if line_count > MAX_HEADER_LINES:
                    break
        if header_lines:
            for i in eval_order:
                msg.debug("> attempt", date_formats[i])
                if date_formats[i]:
                    tmp_fmt = date_formats[i][0]
                    tmp_trim = date_formats[i][1]

                    tmp_now = dt.now().strftime(tmp_fmt)
                    if tmp_trim != 0:
                        tmp_now = tmp_now[:tmp_trim]

                    for line in header_lines:
                        dummy, exception, dummy = _parse_log_line(line, date_formats[i])
                        if exception == 0:
                            idx_date = i
                            date_info = date_formats[i]
                            break
                if idx_date > 0:
                    break

            msg.debug("> use", "idx_date={}, header_lines={}, date_info={}".format(idx_date, len(header_lines), date_info))
        else:
            empty = 1
            msg.debug("> emtpy", "idx_date={}, empty_file={}".format(idx_date, empty))

        return empty, idx_date

    def _parse_log_line(line, date_info):
        EX_OK = 0
        t_fmt = date_info[0]
        t_trim = date_info[1]
        try:
            # Attempt to parse the timestamp from the beginning of the line
            timestamp_str = line[:t_trim]
            timestamp = dt.strptime(timestamp_str, t_fmt)
            return EX_OK, 0, (timestamp, line)
        except ValueError:
            # If timestamp parsing fails, treat it as a non-timestamped line
            # and place it at the end of the sorted output (or handle as needed)
            return EX_OK, 1, (dt.max, line) # Puts non-timestamped lines last

    for log_file in log_files.keys():
        f_names = []
        all_lines = []
        subfolders = [ f.path for f in os.scandir(report_data['source_data']['dirpath_data_source']) if f.is_dir() ]
        for dirpath in subfolders:
            f_path = dirpath + "/" + log_file
            if os.path.exists(f_path):
                f_names.append(f_path)
        len_f_names = len(f_names)

        if len_f_names > 0:
            combined_notes = []
            f_combined_path = report_data['source_data']['dirpath_reports'] + "/combined." + log_file
            msg.min(" Combining {} File(s)".format(len_f_names), f_combined_path)
            t_parse_exceptions = 0
            empty_files = 0
            unsorted_files = 0
            for f_path in f_names:
                empty, idx_date = _get_date_format(f_path, date_formats, log_files[log_file])
                combined_notes.append("{}: {}".format(date_formats[idx_date], f_path))
                if empty > 0:
                    msg.verbose(" Empty file", f_path)
                    combined_notes.append(" Empty file")
                    empty_files += 1
                    continue
                elif idx_date == 0:
                    msg.verbose(" Skipping", f_path)
                    combined_notes.append(" Skipped file, missing known date_formats")
                    unsorted_files += 1
                    continue
                
                # Read and parse lines from the each file in f_names
                _rc = EX_OK
                len_before = len(all_lines)
                with open(f_path, 'r') as f:
                    msg.debug("> parse", log_file)
                    for line in f:
                        line = line.strip()
                        _rc, exception, _line_parts = _parse_log_line(line, date_formats[idx_date])
                        t_parse_exceptions += exception
                        all_lines.append(_line_parts)
                len_after = len(all_lines)

                msg.debug(">", "len_before={}, len_after={}, _rc={}".format(len_before, len_after, _rc))
                if len_after > 0 and t_parse_exceptions == len_after:
                    break
                

            msg.debug(">", "all_lines={}, t_parse_exceptions={}, empty_files={}, unsorted_files={}, total files={}".format(len(all_lines), t_parse_exceptions, empty_files, unsorted_files, len_f_names))
            with open(f_combined_path, 'w') as outfile:
                for line in combined_notes:
                    outfile.write(line + '\n')
                outfile.write('\n\n')

            if empty_files == len_f_names:
                msg.min(" Warning", "All {} files were empty".format(log_file))
            elif empty_files > 0:
                msg.min(" Note", "{} of {} {} files were empty".format(empty_files, len_f_names, log_file))
            if unsorted_files == len_f_names:
                msg.min(" Skipping", "All {} files could not be sorted, unexpected time format".format(log_file))
            elif unsorted_files > 0:
                msg.min(" Note", "{} of {} {} files could not be sorted and were skipped, unexpected time format".format(unsorted_files, len_f_names, log_file))

            # Sort all log entries by their parsed timestamps
            if all_lines:
                all_lines.sort(key=lambda x: x[0])
                with open(f_combined_path, 'a') as outfile:
                    for timestamp, line in all_lines:
                        outfile.write(line + '\n')
        else:
            msg.debug("Warning", "No {} files found".format(log_file))


def analyze_cluster(msg, report_data):
    report_file = report_data['source_data']['dirpath_reports'] + "/report_data.json"
    try:
        with open(report_file, "w") as f:
            json.dump(report_data, f, indent = 4)
    except Exception as e:
        msg.min(" ERROR:", "Cannot write {} file - {}".format(report_file, str(e)))
        sys.exit(13)
    msg.min("Cluster Report Data File", report_file)

    if report_data['source_data']['combine_logs'] is True:
        synchronize_log_files(msg, report_data)

##############################################################################
# Main
##############################################################################

def main(argv):
    '''main entry point'''
    global SVER, progress_bar_active, config_file, tool_name
    global width, description_width
    VALID_MIME_TYPES = [ 'application/x-xz', 'application/x-bzip', 'application/x-bzip2','application/x-gzip', 'application/x-tar' ]

    report_data = { 'tool_name': tool_name, 'tool_version': SVER }
    this_file_data = {}
    this_cluster_data = {}
    remove_archive = False
    remove_extracted_directory = True
    pattern_library = False
    combine_logs = True
    given_type = ''
    given_report_output_path = {}
    given_extract_path = {}
    extract_path = ''
    report_output_path = ''

    if( os.path.exists(config_file) ):
        config.read(config_file)
        width = int(config_entry(config.get("Common", "display_width")))
        description_width = int(config_entry(config.get("Common", "description_width")))
        tool_library_path = config_entry(config.get("Common", "tool_library_path"), '/')
        extract_path = config_entry(config.get("Common", "extract_path"), '/')
        report_output_path = config_entry(config.get("Common", "report_output_path"), '/')
        msg.set_width(description_width)
        config_logging = msg.validate_level(config_entry(config.get("Common", "log_level")))
        if( config_logging >= msg.LOG_QUIET ):
            msg.set_level(config_logging)
        else:
            msg.verbose("Warning: Invalid log level in config file, using instance default")
    else:
        title()
        print("Error: File not found - " + config_file + "\n")
        sys.exit(1)

    os.environ['PYTHONPATH'] = os.path.abspath(tool_library_path + 'python')

    try:
        (optlist, args) = getopt.gnu_getopt(argv[1:], "hbcdkno:pl:qrvx:", ["help", "batch", "dont_combine", "debug", "keep", "normal", "output=", "summary", "log_level=", "quiet", "remove", "verbose", "dirpath_extract_here="])
    except getopt.GetoptError as exc:
        title()
        print("Error:", exc, file=sys.stderr)
        print()
        usage()
        sys.exit(2)
    for opt, arg in optlist:
        if opt in {"-h", "--help"}:
            title()
            usage()
            sys.exit(0)
        elif opt in {"-b", "--batch"}:
            progress_bar_active = False
        elif opt in {"-c", "--dont_combine"}:
            combine_logs = False
        elif opt in {"-d", "--debug"}:
            msg.set_level(msg.LOG_DEBUG)
            remove_extracted_directory = False
        elif opt in {"-k", "--keep"}:
            remove_extracted_directory = False
        elif opt in {"-n", "--normal"}:
            msg.set_level(msg.LOG_NORMAL)
        elif opt in {"-o", "--output"}:
            given_report_output_path = arg
        elif opt in {"-r", "--remove"}:
            remove_archive = True
        elif opt in {"-q", "--quiet"}:
            msg.set_level(msg.LOG_QUIET)
        elif opt in {"-v", "--verbose"}:
            msg.set_level(msg.LOG_VERBOSE)
        elif opt in {"-x", "--dirpath_extract_here"}:
            given_extract_path = arg
        elif opt in {"-l", "--log_level"}:
            user_logging = msg.validate_level(arg)
            if( user_logging >= msg.LOG_QUIET ):
                msg.set_level(user_logging)
            else:
                print("Warning: Invalid log level, using instance default")

    if( msg.get_level() > msg.LOG_QUIET ):
        title()

    if pattern_library:
        show_pattern_library(msg, sca_patterns_path)
        sys.exit(0)

    preconfigured_extraction_path = check_extraction_path_given(msg, config_file, given_extract_path, extract_path)
    preconfigured_report_path = check_report_path_given(msg, config_file, given_report_output_path, report_output_path)

    total_args_given = len(args)
    archive_dir = ''
    count = 0

    if total_args_given > 0:
        for given_source in args:
            msg.normal("Checking", given_source)
            this_file_data = evaluate_given_path(msg, given_source)
            this_file_data['extract_here_for_reports'] = False
            this_file_data['remove_tarball'] = False
            this_file_data['remove_directory'] = False
            this_file_data['combine_logs'] = combine_logs
            
            if this_file_data['exists']:
                count += 1
                if total_args_given > 1:
                    msg.min("Processing [{}/{}]".format(count, total_args_given), this_file_data['path'])
                else:
                    msg.min("Processing", this_file_data['path'])

                if this_file_data['type'] == 'dir':
                    this_file_data['remove_directory'] = remove_archive
                    if valid_archive_dir(msg, this_file_data['path']):
                        this_file_data['valid'] = True
                        this_file_data['dirpath_data_source'] = this_file_data['path']
                        if preconfigured_report_path:
                            this_file_data['dirpath_reports'] = preconfigured_report_path['path']
                        else:
                            if this_file_data['head_write']:    
                                this_file_data['dirpath_reports'] = this_file_data['path'] + "_reports"
                            else:
                                msg.min(" ", "Write permisson denied, cannot create report file in {0}".format(this_file_data['head']))
                                msg.min(" * Suggestion", "Use -o, --output to specify an alternate report file directory")
                                separate_entry(msg, total_args_given)
                                continue
                        this_file_data['dirpath_data_source'] = this_file_data['path']
                        _create_reports_path(msg, this_file_data)
                        report_data['source_data'] = this_file_data
                        this_cluster_data = get_cluster_data(msg, this_file_data)
                        report_data['cluster'] = this_cluster_data
                        analyze_cluster(msg, report_data)
                    else:
                        this_file_data['valid'] = False
                        report_data['source_data'] = this_file_data
                    separate_entry(msg, total_args_given)

                elif this_file_data['type'] == 'file':
                    if not this_file_data['tail_mime_type'] in VALID_MIME_TYPES:
                        msg.min(" Missing file", "Not an HB report compressed file - {0}".format(this_file_data['path']))
                        separate_entry(msg, total_args_given)
                        continue
                    this_file_data['remove_tarball'] = remove_archive
                    this_file_data['remove_directory'] = remove_extracted_directory

                    if preconfigured_extraction_path:
                        this_file_data['dirpath_extract_here'] = preconfigured_extraction_path['dirpath_extract_here']
                        this_file_data['extract_here_for_reports'] = preconfigured_extraction_path['extract_here_for_reports']
                    else:
                        if this_file_data['head_write']:
                            this_file_data['dirpath_extract_here'] = this_file_data['head']
                        else:
                            msg.min(" ERROR:", "Write permisson denied, cannot extract file to {0}".format(this_file_data['head']))
                            msg.min(" * Suggestion", "Use -x, --dirpath_extract_here to specify an alternate extraction directory")
                            separate_entry(msg, total_args_given)
                            continue
                    archive_dir = extract_archive(msg, this_file_data)
                    msg.debug("archive_dir", archive_dir)
                    if valid_archive_dir(msg, archive_dir):
                        this_file_data['valid'] = True
                        this_file_data['dirpath_embedded'] = archive_dir
                        this_file_data['dirpath_data_source'] = this_file_data['dirpath_embedded']

                        if preconfigured_report_path:
                            this_file_data['dirpath_reports'] = preconfigured_report_path['path']
                        else:
                            if this_file_data['extract_here_for_reports']:
                                this_file_data['dirpath_reports'] = this_file_data['dirpath_extract_here']
                            else:
                                if this_file_data['head_write']:
                                    this_file_data['dirpath_reports'] = this_file_data['path'] + "_reports"
                                else:
                                    msg.min(" ERROR:", "Write permisson denied, cannot create report file in {0}".format(this_file_data['head']))
                                    msg.min(" * Suggestion", "Use -o, --output to specify an alternate report file directory")
                                    separate_entry(msg, total_args_given)
                                    continue
                        _create_reports_path(msg, this_file_data)
                        report_data['source_data'] = this_file_data
                        this_cluster_data = get_cluster_data(msg, this_file_data)
                        report_data['cluster'] = this_cluster_data
                        analyze_cluster(msg, report_data)
                    else:
                        this_file_data['valid'] = False
                        report_data['source_data'] = this_file_data
                    separate_entry(msg, total_args_given)

                elif not this_file_data['tail_read']:
                    msg.min(" ERROR:", "Read permisson denied - {0}".format(this_file_data['path']))
                    msg.min(" * Suggestion", "Use chmod or sudo to elevate read permissions")
                    separate_entry(msg, total_args_given)
                    continue
                else:
                    msg.min(" ERROR:", "Unknown file type - {0}".format(this_file_data['path']))
                    separate_entry(msg, total_args_given)
                    continue
                clean_up(msg, report_data)
            else:
                msg.min('Error: File or directory not found - {}'.format(given_source))
        msg.normal()
    else:
        usage()
        sys.exit(0)

    msg.min()

# Entry point
if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation())
    msg = DisplayMessages()
    main(sys.argv)

